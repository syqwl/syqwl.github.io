<div class="paper-box">
  <div class="paper-box-image">
    <div>
      <div class="badge">ICML 2026 (Conference Submission)</div>
      <img src="/static/assets/publication1.png" alt="Uni-SLTP" width="100%">
    </div>
  </div>
  <div class="paper-box-text">
    <p>Bridging the Gap Between Semantics and Reconstruction: Unifying Sign Language Translation and Production</p>
    <p>Xiao Liu, Shiwei Gan, Yafeng Yin, Jiaxin Yin, <strong>Yaqi Sun</strong>, Bowen Guo, Zhiwei Jiang, Lei Xie, Sanglu Lu</p>
    <p><em>手语翻译(SLT)与手语生成(SLP)是手语-文本映射的两个相反方向，却通常被置于各自独立的流程中研究。我们将二者统一于单一条件序列建模视角，提出 Uni-SLTP，通过共享离散姿态词符空间学习双向映射。为弥合“语义-重建鸿沟”，我们引入分层姿态词符化器 SR-RVQ，将语义锚定流与残差动作流分离。在公开数据集上，Uni-SLTP 在保持竞争性 SLT 性能的同时实现了更优的 SLP 动作精度。</em></p>
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-image">
    <div>
      <div class="badge">KDD 2026 (Conference Submission)</div>
      <img src="/static/assets/publication2.png" alt="Rejection-Aware Best-of-N" width="100%">
    </div>
  </div>
  <div class="paper-box-text">
    <p>Rejection-Aware Best-of-N Speculation with Shared Prefix Caching</p>
    <p>Rui Ning, Zuxi Chen, Chao Fang, <strong>Yaqi Sun</strong>, Xue Li, Zhibin Wang, Rong Gu, Sheng Zhong, Chen Tian</p>
    <p><em>本文提出一种结合拒绝感知的 Best-of-N 推测解码与共享前缀缓存的方法，以提升大语言模型推理效率。</em></p>
  </div>
</div>
